# Z.ai Chat Provider for VS Code

[![CI](https://github.com/Ryosuke-Asano/zai-provider-extension/actions/workflows/ci.yml/badge.svg)](https://github.com/Ryosuke-Asano/zai-provider-extension/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![npm version](https://img.shields.io/npm/v/zai-vscode-chat.svg)](https://www.npmjs.com/package/zai-vscode-chat)

A Visual Studio Code extension that integrates [Z.ai](https://z.ai) models (GLM-4.7, GLM-4.7 Flash) into GitHub Copilot Chat using the Language Model Chat Provider API.

## Features

- **Multiple Model Support**: Access to Z.ai's latest GLM models
  - **GLM-4.7**: High-performance text model (200K context)
  - **GLM-4.7 Flash**: Fast, cost-effective model (200K context)

- **Tool Calling**: Full support for function calling and external tools
- **Streaming Responses**: Real-time response streaming for better UX
- **Vision Support**: Image analysis capabilities for all models (via GLM-OCR API)
- **Thinking Process Display**: View model's reasoning in collapsible sections (GLM-4.7 / GLM-4.7 Flash)
- **Detailed Logging**: Progress indicators for image analysis and reasoning process
- **BYOK (Bring Your Own Key)**: Use your own Z.ai API key
- **Secure API Key Storage**: Uses VS Code's secret storage for your API keys
- **Easy Configuration**: Simple command to manage your Z.ai API key

## Requirements

- Visual Studio Code 1.104.0 or higher
- GitHub Copilot (Free, Pro, or Pro+ plan)
- Z.ai API key (get one at [https://z.ai](https://z.ai))

## Quick Start

1. **Install the Extension**
   - Search for "Z.ai Chat Provider" in the VS Code Extensions Marketplace
   - Or build and install via VSIX:

     ```bash
     # Build the extension
     pnpm run package

     # Install the generated .vsix file
     code --install-extension zai-vscode-chat-*.vsix
     ```

2. **Get Your API Key**
   - Visit [Z.ai](https://z.ai) and sign up for an account
   - Navigate to API settings to generate your API key

3. **Configure the Extension**
   - Open the Command Palette (`Ctrl+Shift+P` or `Cmd+Shift+P`)
   - Run: `Z.ai: Manage Z.ai Provider`
   - Enter your Z.ai API key when prompted

4. **Start Chatting**
   - Open GitHub Copilot Chat (`Ctrl+Alt+I` or `Cmd+Alt+I`)
   - Select a Z.ai model from the model selector
   - Start chatting!

## Model Capabilities

| Model             | Context Window | Max Output | Tool Calling | Vision       | Thinking |
| ----------------- | -------------- | ---------- | ------------ | ------------ | -------- |
| **GLM-4.7**       | 200K           | 128K       | âœ…           | âœ… (via OCR) | âœ…       |
| **GLM-4.7 Flash** | 200K           | 131K       | âœ…           | âœ… (via OCR) | âœ…       |

## Vision Support

This extension provides vision capabilities for all Z.ai models using the GLM-OCR API:

- **GLM-4.7 / GLM-4.7 Flash**: Image analysis via GLM-OCR API with automatic text conversion

### How It Works

When you send images with Z.ai models, the extension follows a best-effort flow that matches the current implementation:

1. Attempts to extract image bytes from the message parts via the VS Code APIs. If byte data is available the extension converts it to a `data:` URL (`data:<mime>;base64,...`).
2. Sends the image data URL to Z.ai (GLM-OCR / vision endpoint) via the MCP/vision tool or the `glm-4.6v` vision model to perform layout parsing and analysis.
3. Converts the analysis into detailed text descriptions (including structured content like charts, tables, and documents) and adds them to the chat message content.
4. The model responds using the augmented chat context (the original text plus the image descriptions).

Notes:

- If raw image bytes are not available from the editor or input, the extension will fall back to available vision-capable models (for example `glm-4.6v`) or a best-effort OCR path. The extension logs warnings when it cannot obtain image byte data.
- Image data is sent to Z.ai using the user's API key; review your privacy and API usage settings if this is a concern.

### Developer Console Logs

When images are being analyzed, you can see detailed progress logs in the VS Code Developer Tools console:

- ğŸ–¼ï¸ Starting image analysis...
- ğŸ“¡ Sending request to GLM-OCR API...
- â±ï¸ Response received with timing
- âœ… Analysis completed with response length and total time
- âŒ Error information if analysis fails

## Thinking Process Display

For GLM-4.7 and GLM-4.7 Flash models, you can now see the model's reasoning process displayed in a collapsible section:

```
<details open>
  <summary>ğŸ§  Thinking Process</summary>

  (Model's step-by-step reasoning shown here)

</details>

(The final answer)
```

### Developer Console Logs

When reasoning is in progress, you can see detailed progress logs:

- ğŸš€ Starting chat request with thinking enabled
- ğŸ§  Starting reasoning/thinking process...
- ğŸ“¦ Emitting reasoning content with length

### Configuration

You can configure the thinking display behavior in VS Code settings:

- **`zai.enableThinking`** (default: `true`)
  - When `true`: Shows the model's thinking/reasoning process in a collapsible section
  - When `false`: Hides the thinking process, showing only the final answer

To change this setting:

1. Open VS Code Settings (`Cmd+,` or `Ctrl+,`)
2. Search for "zai.enableThinking"
3. Toggle the setting on or off

## Development

```bash
# Clone the repository
git clone https://github.com/Ryosuke-Asano/zai-provider-extension.git
cd zai-provider-extension

# Install dependencies
pnpm install

# Compile TypeScript
pnpm run compile

# Watch for changes
pnpm run watch

# Run in VS Code Extension Development Host
# Press F5 in VS Code
```

## Project Structure

```
zai-provider-extension/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extension.ts      # Extension entry point
â”‚   â”œâ”€â”€ mcp.ts            # MCP client (vision/OCR)
â”‚   â”œâ”€â”€ provider.ts       # LanguageModelChatProvider implementation
â”‚   â”œâ”€â”€ utils.ts          # Utility functions
â”‚   â””â”€â”€ types.ts          # Type definitions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ mcp.test.ts       # MCP client tests
â”‚   â”œâ”€â”€ types.test.ts     # Type definitions tests
â”‚   â””â”€â”€ utils.test.ts     # Utility function tests
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ make-icon.js      # Icon generation script
â”œâ”€â”€ __mocks__/
â”‚   â””â”€â”€ vscode.ts         # VS Code API mocks
â”œâ”€â”€ package.json          # Extension manifest
â”œâ”€â”€ tsconfig.json         # TypeScript configuration
â”œâ”€â”€ tsconfig.test.json    # Test TypeScript configuration
â”œâ”€â”€ jest.config.js        # Jest test configuration
â”œâ”€â”€ eslint.config.mjs     # ESLint configuration
â”œâ”€â”€ .prettierrc           # Prettier configuration
â””â”€â”€ README.md
```

## API Configuration

The extension uses the Z.ai Coding Plan API:

- **Endpoint**: `https://api.z.ai/api/coding/paas/v4`
- **Compatible with**: OpenAI API format

## Available Scripts

```bash
# Compile TypeScript
pnpm run compile

# Watch for changes and recompile automatically
pnpm run watch

# Run ESLint
pnpm run lint

# Run ESLint with auto-fix
pnpm run lint:fix

# Format code with Prettier
pnpm run format

# Check code formatting
pnpm run format:check

# Run tests
pnpm run test

# Run tests in watch mode
pnpm run test:watch

# Run tests with coverage report
pnpm run test:coverage

# Package the extension
pnpm run package

# Publish the extension
pnpm run publish
```

## Getting a Z.ai API Key

1. Visit [https://z.ai](https://z.ai)
2. Sign up or log in to your account
3. Navigate to the API section
4. Generate a new API key
5. Use the key in this extension via the `Z.ai: Manage Z.ai Provider` command

## Troubleshooting

### "Z.ai API key not found"

- Run the `Z.ai: Manage Z.ai Provider` command to enter your API key

### "Message exceeds token limit"

- Reduce the length of your message or conversation history
- Large tool outputs or attachments can inflate the prompt; retry with fewer/shorter tool results
- Try a model with a larger context window

### Models not appearing in Copilot Chat

- Ensure you have VS Code 1.104.0 or higher installed
- Verify that GitHub Copilot is enabled and you're logged in
- Check that the extension is activated (no errors in the dev tools console)

### Vision & GLM-4.6V fallback

- The extension uses an internal `GLM-4.6v` model for native vision support as a fallback; it is not exposed in the model selector.
- Due to VS Code API limitations, image data is not accessible to extensions
- VS Code provides only ephemeral references to images, not the actual image bytes
- This is a platform limitation that affects all Language Model Chat Provider extensions
- Vote for [VS Code issue](https://github.com/microsoft/vscode/issues) to request image data access for extensions

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Support

For issues, questions, or suggestions:

- Open an issue on GitHub
- Check the [Z.ai documentation](https://docs.z.ai)

## Acknowledgments

- Built with [VSCode Language Model Chat Provider API](https://code.visualstudio.com/api/extension-guides/ai/language-model-chat-provider)
- Inspired by [Hugging Face Provider for GitHub Copilot Chat](https://github.com/huggingface/huggingface-vscode-chat)

**VISION**

Z.ai Chat Provider ã¯ã€Z.ai ã®æœ€æ–° GLM ç³»ãƒ¢ãƒ‡ãƒ«ã‚’ GitHub Copilot Chat ã«çµ±åˆã—ã€é–‹ç™ºè€…ãŒé«˜æ€§èƒ½ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ã‚„ã‚Šå–ã‚Šã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ç¾çŠ¶ã®å®Ÿè£…ã§ã¯ä»¥ä¸‹ã‚’é‡è¦–ã—ã¦ã„ã¾ã™ã€‚

- **å®Ÿç”¨çš„ãªãƒ¢ãƒ‡ãƒ«çµ±åˆ**: GLM-4.7 ç³»ï¼ˆGLM-4.7 / GLM-4.7 Flashï¼‰ã‚’å„ªå…ˆã‚µãƒãƒ¼ãƒˆã—ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ200Kï¼‰ã‚„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã€é–¢æ•°å‘¼ã³å‡ºã—ã‚’æ´»ç”¨ã—ãŸå®Ÿå‹™çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚
- **ç”»åƒï¼ˆVisionï¼‰å¯¾å¿œ**: GLM-OCR ãƒ™ãƒ¼ã‚¹ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æã‚’ä»‹ã—ã¦ç”»åƒå…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã€ãƒãƒ£ãƒƒãƒˆå†…ã§ç”»åƒå†…å®¹ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¶ç´„ã«ã‚ˆã‚Šä¸€éƒ¨ã¯ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§å‡¦ç†ã•ã‚Œã¾ã™ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’æãªã‚ãªã„ã‚ˆã†é€²æ—è¡¨ç¤ºã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚
- **é–‹ç™ºè€…å‘ã‘è¨­è¨ˆ**: API ã‚­ãƒ¼ã®å®‰å…¨ãªä¿ç®¡ã€è¨­å®šã®ä½¿ã„ã‚„ã™ã•ã€è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›ã¨ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å‚™ãˆã€æ‹¡å¼µãƒ»ãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ã„ã‚³ãƒ¼ãƒ‰æ§‹é€ ã‚’ç¶­æŒã—ã¾ã™ã€‚
- **ç¾å®Ÿçš„ãªåˆ¶ç´„ã®æ˜ç¤º**: VS Code ã®æ‹¡å¼µ API ã®åˆ¶ç´„ï¼ˆç”»åƒãƒã‚¤ãƒŠãƒªã¸ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã‚‹ç­‰ï¼‰ã‚’è¸ã¾ãˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œã‚„é–‹ç™ºè€…å‘ã‘ã®æ³¨æ„ç‚¹ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–ã—ã¦ã„ã¾ã™ã€‚

ä»Šå¾Œã®æ–¹å‘æ€§ã¨ã—ã¦ã¯ã€ã‚ˆã‚Šåºƒã„ãƒ¢ãƒ‡ãƒ«é¸æŠè‚¢ã®æä¾›ã€ãƒ­ãƒ¼ã‚«ãƒ«ã¾ãŸã¯ã‚ˆã‚Šãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¿½æ±‚ã€ãã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«å¿œã˜ãŸ UX æ”¹å–„ã‚’è¨ˆç”»ã—ã¦ã„ã¾ã™ã€‚
